{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiwtNgENbx2g"
   },
   "source": [
    "This notebook trains a sequence to sequence (seq2seq) model for  English to Spanish translation. This is an advanced example that assumes some knowledge of sequence to sequence models.\n",
    "\n",
    "After training the model in this notebook, you will be able to input English  sentence, such as  and return the English translation\n",
    "\n",
    "The translation quality is reasonable and not great, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69231</td>\n",
       "      <td>I want to talk to you about Tom.</td>\n",
       "      <td>Quiero hablar contigo sobre Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75461</td>\n",
       "      <td>Did you feed the dog this morning?</td>\n",
       "      <td>¿Diste de comer al perro esta mañana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80335</td>\n",
       "      <td>Nobody speaks like this in Germany.</td>\n",
       "      <td>Nadie habla así en Alemania.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17726</td>\n",
       "      <td>The men go to work.</td>\n",
       "      <td>Los hombres van a trabajar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63123</td>\n",
       "      <td>Tom was dressed appropriately.</td>\n",
       "      <td>Tom estaba vestido para la ocasión.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    source  \\\n",
       "69231     I want to talk to you about Tom.   \n",
       "75461   Did you feed the dog this morning?   \n",
       "80335  Nobody speaks like this in Germany.   \n",
       "17726                  The men go to work.   \n",
       "63123       Tom was dressed appropriately.   \n",
       "\n",
       "                                      target  \n",
       "69231       Quiero hablar contigo sobre Tom.  \n",
       "75461  ¿Diste de comer al perro esta mañana?  \n",
       "80335           Nadie habla así en Alemania.  \n",
       "17726            Los hombres van a trabajar.  \n",
       "63123    Tom estaba vestido para la ocasión.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "lines_raw= pd.read_table(data_path,names=['source', 'target'])\n",
    "lines_raw.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Clean and Preprocess the text__\n",
    "1. Convert to lower case\n",
    "2. Convert special characters\n",
    "3. Remove Digits\n",
    "4. Remove spaces\n",
    "5. Add start_ and end_ tags to each sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= sentence.strip()\n",
    "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence=  'start_ ' + sentence + ' _end'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ may i borrow this book ? _end\n",
      "b'start_ \\xc2\\xbf puedo tomar prestado este libro ? _end'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opI2GzOt479E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ may i borrow this book ? _end\n",
      "b'start_ \\xc2\\xbf puedo tomar prestado este libro ? _end'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "  \n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  #print(lines)\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  print(path)\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTbSbBz55QtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spa.txt\n",
      "start_ can you please leave me alone ? _end\n",
      "start_ ¿ me puedes dejar solo ,  por favor ? _end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size=60000\n",
    "source, target = create_dataset(data_path, sample_size)\n",
    "print(source[-1])\n",
    "print(target[-1])\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmMZQpdO60dt"
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "  return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the source and ttarget toekns and post pad them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "source_sentence_tokenizer.fit_on_texts(source)\n",
    "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
    "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "target_sentence_tokenizer.fit_on_texts(target)\n",
    "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
    "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n",
    "print(len(target_tensor[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "\n",
    " To train faster, we can limit the size of the dataset using **sample_size** sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "max_target_length= max(len(t) for t in  target_tensor)\n",
    "print(max_target_length)\n",
    "max_source_length= max(len(t) for t in  source_tensor)\n",
    "print(max_source_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QILQkOs3jFG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 48000 12000 12000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_tensor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXukARTDd7MT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> start_\n",
      "4 ----> i\n",
      "39 ----> know\n",
      "7 ----> tom\n",
      "10 ----> is\n",
      "27 ----> your\n",
      "228 ----> friend\n",
      "3 ----> .\n",
      "2 ----> _end\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> start_\n",
      "75 ----> sé\n",
      "12 ----> que\n",
      "6 ----> tom\n",
      "9 ----> es\n",
      "42 ----> tu\n",
      "219 ----> amigo\n",
      "3 ----> .\n",
      "2 ----> _end\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert( target_sentence_tokenizer, target_train_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(source_train_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 13]), TensorShape([64, 20]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations]\n",
    "The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 13, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k534zTHiDjQU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5UY8wko3jFp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 15482)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddefjBMa3jF0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 loss 0.6956598162651062\n",
      "Epoch 1 Batch 100 loss 0.763929009437561\n",
      "Epoch 1 Batch 200 loss 0.6837393045425415\n",
      "Epoch 1 Batch 300 loss 0.6682395339012146\n",
      "Epoch 1 Batch 400 loss 0.6507248282432556\n",
      "Epoch 1 Batch 500 loss 0.5799139142036438\n",
      "Epoch 1 Batch 600 loss 0.6264998316764832\n",
      "Epoch 1 Batch 700 loss 0.6814857721328735\n",
      "Epoch 1 Loss 0.6441\n",
      "Time taken for 1 epoch 1578.9207246303558 sec\n",
      "\n",
      "Epoch 2 Batch 0 loss 0.4790405333042145\n",
      "Epoch 2 Batch 100 loss 0.4956303536891937\n",
      "Epoch 2 Batch 200 loss 0.42530933022499084\n",
      "Epoch 2 Batch 300 loss 0.38007795810699463\n",
      "Epoch 2 Batch 400 loss 0.45016881823539734\n",
      "Epoch 2 Batch 500 loss 0.3710222840309143\n",
      "Epoch 2 Batch 600 loss 0.3610090911388397\n",
      "Epoch 2 Batch 700 loss 0.44673362374305725\n",
      "Epoch 2 Loss 0.4331\n",
      "Time taken for 1 epoch 1565.6961843967438 sec\n",
      "\n",
      "Epoch 3 Batch 0 loss 0.2985133230686188\n",
      "Epoch 3 Batch 100 loss 0.22902511060237885\n",
      "Epoch 3 Batch 200 loss 0.29360195994377136\n",
      "Epoch 3 Batch 300 loss 0.31069430708885193\n",
      "Epoch 3 Batch 400 loss 0.31368520855903625\n",
      "Epoch 3 Batch 500 loss 0.314592570066452\n",
      "Epoch 3 Batch 600 loss 0.26923441886901855\n",
      "Epoch 3 Batch 700 loss 0.26498663425445557\n",
      "Epoch 3 Loss 0.3014\n",
      "Time taken for 1 epoch 1561.9637155532837 sec\n",
      "\n",
      "Epoch 4 Batch 0 loss 0.19859014451503754\n",
      "Epoch 4 Batch 100 loss 0.15931178629398346\n",
      "Epoch 4 Batch 200 loss 0.1853380650281906\n",
      "Epoch 4 Batch 300 loss 0.23516805469989777\n",
      "Epoch 4 Batch 400 loss 0.2201475203037262\n",
      "Epoch 4 Batch 500 loss 0.21784336864948273\n",
      "Epoch 4 Batch 600 loss 0.23990924656391144\n",
      "Epoch 4 Batch 700 loss 0.24434028565883636\n",
      "Epoch 4 Loss 0.2196\n",
      "Time taken for 1 epoch 1562.8336188793182 sec\n",
      "\n",
      "Epoch 5 Batch 0 loss 0.13347643613815308\n",
      "Epoch 5 Batch 100 loss 0.1744602769613266\n",
      "Epoch 5 Batch 200 loss 0.18049345910549164\n",
      "Epoch 5 Batch 300 loss 0.1476294845342636\n",
      "Epoch 5 Batch 400 loss 0.1762777417898178\n",
      "Epoch 5 Batch 500 loss 0.1424569934606552\n",
      "Epoch 5 Batch 600 loss 0.17855426669120789\n",
      "Epoch 5 Batch 700 loss 0.17868809401988983\n",
      "Epoch 5 Loss 0.1703\n",
      "Time taken for 1 epoch 1567.0091602802277 sec\n",
      "\n",
      "Epoch 6 Batch 0 loss 0.09853958338499069\n",
      "Epoch 6 Batch 100 loss 0.11140880733728409\n",
      "Epoch 6 Batch 200 loss 0.11089277267456055\n",
      "Epoch 6 Batch 300 loss 0.14755406975746155\n",
      "Epoch 6 Batch 400 loss 0.1523357629776001\n",
      "Epoch 6 Batch 500 loss 0.12762518227100372\n",
      "Epoch 6 Batch 600 loss 0.12148886173963547\n",
      "Epoch 6 Batch 700 loss 0.18081645667552948\n",
      "Epoch 6 Loss 0.1374\n",
      "Time taken for 1 epoch 1589.0822985172272 sec\n",
      "\n",
      "Epoch 7 Batch 0 loss 0.10463931411504745\n",
      "Epoch 7 Batch 100 loss 0.07924025505781174\n",
      "Epoch 7 Batch 200 loss 0.09976129233837128\n",
      "Epoch 7 Batch 300 loss 0.1252477467060089\n",
      "Epoch 7 Batch 400 loss 0.11361709982156754\n",
      "Epoch 7 Batch 500 loss 0.11304068565368652\n",
      "Epoch 7 Batch 600 loss 0.15494593977928162\n",
      "Epoch 7 Batch 700 loss 0.1335686594247818\n",
      "Epoch 7 Loss 0.1163\n",
      "Time taken for 1 epoch 1566.928725719452 sec\n",
      "\n",
      "Epoch 8 Batch 0 loss 0.07292342185974121\n",
      "Epoch 8 Batch 100 loss 0.08750928938388824\n",
      "Epoch 8 Batch 200 loss 0.0947294682264328\n",
      "Epoch 8 Batch 300 loss 0.07403752207756042\n",
      "Epoch 8 Batch 400 loss 0.09935609996318817\n",
      "Epoch 8 Batch 500 loss 0.1140831708908081\n",
      "Epoch 8 Batch 600 loss 0.1006072387099266\n",
      "Epoch 8 Batch 700 loss 0.1372491419315338\n",
      "Epoch 8 Loss 0.1026\n",
      "Time taken for 1 epoch 1563.771032333374 sec\n",
      "\n",
      "Epoch 9 Batch 0 loss 0.11906315386295319\n",
      "Epoch 9 Batch 100 loss 0.07181496918201447\n",
      "Epoch 9 Batch 200 loss 0.08593986183404922\n",
      "Epoch 9 Batch 300 loss 0.09550050646066666\n",
      "Epoch 9 Batch 400 loss 0.11426593363285065\n",
      "Epoch 9 Batch 500 loss 0.12207403033971786\n",
      "Epoch 9 Batch 600 loss 0.1086326614022255\n",
      "Epoch 9 Batch 700 loss 0.11260179430246353\n",
      "Epoch 9 Loss 0.0934\n",
      "Time taken for 1 epoch 1583.3373453617096 sec\n",
      "\n",
      "Epoch 10 Batch 0 loss 0.06380419433116913\n",
      "Epoch 10 Batch 100 loss 0.07672788947820663\n",
      "Epoch 10 Batch 200 loss 0.0833241418004036\n",
      "Epoch 10 Batch 300 loss 0.07058285921812057\n",
      "Epoch 10 Batch 400 loss 0.061833180487155914\n",
      "Epoch 10 Batch 500 loss 0.11215517669916153\n",
      "Epoch 10 Batch 600 loss 0.10398677736520767\n",
      "Epoch 10 Batch 700 loss 0.08847278356552124\n",
      "Epoch 10 Loss 0.0850\n",
      "Time taken for 1 epoch 1581.7639336585999 sec\n",
      "\n",
      "Epoch 11 Batch 0 loss 0.09807384014129639\n",
      "Epoch 11 Batch 100 loss 0.05704211816191673\n",
      "Epoch 11 Batch 200 loss 0.07040470093488693\n",
      "Epoch 11 Batch 300 loss 0.06503941863775253\n",
      "Epoch 11 Batch 400 loss 0.08814861625432968\n",
      "Epoch 11 Batch 500 loss 0.07078094035387039\n",
      "Epoch 11 Batch 600 loss 0.08697369694709778\n",
      "Epoch 11 Batch 700 loss 0.09644312411546707\n",
      "Epoch 11 Loss 0.0781\n",
      "Time taken for 1 epoch 1580.928723335266 sec\n",
      "\n",
      "Epoch 12 Batch 0 loss 0.04893769323825836\n",
      "Epoch 12 Batch 100 loss 0.06008072569966316\n",
      "Epoch 12 Batch 200 loss 0.05986136943101883\n",
      "Epoch 12 Batch 300 loss 0.06862585246562958\n",
      "Epoch 12 Batch 400 loss 0.06469748169183731\n",
      "Epoch 12 Batch 500 loss 0.07063938677310944\n",
      "Epoch 12 Batch 600 loss 0.08462698012590408\n",
      "Epoch 12 Batch 700 loss 0.07838835567235947\n",
      "Epoch 12 Loss 0.0750\n",
      "Time taken for 1 epoch 1578.8068327903748 sec\n",
      "\n",
      "Epoch 13 Batch 0 loss 0.04780507832765579\n",
      "Epoch 13 Batch 100 loss 0.07506425678730011\n",
      "Epoch 13 Batch 200 loss 0.0669635459780693\n",
      "Epoch 13 Batch 300 loss 0.04365706816315651\n",
      "Epoch 13 Batch 400 loss 0.09190186858177185\n",
      "Epoch 13 Batch 500 loss 0.07480629533529282\n",
      "Epoch 13 Batch 600 loss 0.08824405819177628\n",
      "Epoch 13 Batch 700 loss 0.09455598145723343\n",
      "Epoch 13 Loss 0.0703\n",
      "Time taken for 1 epoch 1579.6224491596222 sec\n",
      "\n",
      "Epoch 14 Batch 0 loss 0.042537931352853775\n",
      "Epoch 14 Batch 100 loss 0.04090442508459091\n",
      "Epoch 14 Batch 200 loss 0.0656135156750679\n",
      "Epoch 14 Batch 300 loss 0.06367843598127365\n",
      "Epoch 14 Batch 400 loss 0.06462070345878601\n",
      "Epoch 14 Batch 500 loss 0.0647917166352272\n",
      "Epoch 14 Batch 600 loss 0.048681747168302536\n",
      "Epoch 14 Batch 700 loss 0.06959027051925659\n",
      "Epoch 14 Loss 0.0668\n",
      "Time taken for 1 epoch 1568.3426518440247 sec\n",
      "\n",
      "Epoch 15 Batch 0 loss 0.058794260025024414\n",
      "Epoch 15 Batch 100 loss 0.07596663385629654\n",
      "Epoch 15 Batch 200 loss 0.0570196807384491\n",
      "Epoch 15 Batch 300 loss 0.06453122198581696\n",
      "Epoch 15 Batch 400 loss 0.06861153244972229\n",
      "Epoch 15 Batch 500 loss 0.060132499784231186\n",
      "Epoch 15 Batch 600 loss 0.07594899833202362\n",
      "Epoch 15 Batch 700 loss 0.09371814131736755\n",
      "Epoch 15 Loss 0.0640\n",
      "Time taken for 1 epoch 1588.222707748413 sec\n",
      "\n",
      "Epoch 16 Batch 0 loss 0.04829123616218567\n",
      "Epoch 16 Batch 100 loss 0.05064189434051514\n",
      "Epoch 16 Batch 200 loss 0.05422164127230644\n",
      "Epoch 16 Batch 300 loss 0.03945152088999748\n",
      "Epoch 16 Batch 400 loss 0.057806313037872314\n",
      "Epoch 16 Batch 500 loss 0.051085975021123886\n",
      "Epoch 16 Batch 600 loss 0.05425618961453438\n",
      "Epoch 16 Batch 700 loss 0.0492754690349102\n",
      "Epoch 16 Loss 0.0620\n",
      "Time taken for 1 epoch 1590.832799911499 sec\n",
      "\n",
      "Epoch 17 Batch 0 loss 0.05108192190527916\n",
      "Epoch 17 Batch 100 loss 0.05582066997885704\n",
      "Epoch 17 Batch 200 loss 0.03720208629965782\n",
      "Epoch 17 Batch 300 loss 0.06811908632516861\n",
      "Epoch 17 Batch 400 loss 0.05725541338324547\n",
      "Epoch 17 Batch 500 loss 0.056775521486997604\n",
      "Epoch 17 Batch 600 loss 0.08273282647132874\n",
      "Epoch 17 Batch 700 loss 0.06842485070228577\n",
      "Epoch 17 Loss 0.0611\n",
      "Time taken for 1 epoch 1582.2450785636902 sec\n",
      "\n",
      "Epoch 18 Batch 0 loss 0.030635425820946693\n",
      "Epoch 18 Batch 100 loss 0.06697559356689453\n",
      "Epoch 18 Batch 200 loss 0.0713183730840683\n",
      "Epoch 18 Batch 300 loss 0.037884414196014404\n",
      "Epoch 18 Batch 400 loss 0.0482039712369442\n",
      "Epoch 18 Batch 500 loss 0.06328841298818588\n",
      "Epoch 18 Batch 600 loss 0.06330172717571259\n",
      "Epoch 18 Batch 700 loss 0.046605486422777176\n",
      "Epoch 18 Loss 0.0595\n",
      "Time taken for 1 epoch 1576.902646780014 sec\n",
      "\n",
      "Epoch 19 Batch 0 loss 0.06245490908622742\n",
      "Epoch 19 Batch 100 loss 0.02938431315124035\n",
      "Epoch 19 Batch 200 loss 0.049967147409915924\n",
      "Epoch 19 Batch 300 loss 0.02878320775926113\n",
      "Epoch 19 Batch 400 loss 0.055928606539964676\n",
      "Epoch 19 Batch 500 loss 0.06000450998544693\n",
      "Epoch 19 Batch 600 loss 0.05305561050772667\n",
      "Epoch 19 Batch 700 loss 0.07786928117275238\n",
      "Epoch 19 Loss 0.0576\n",
      "Time taken for 1 epoch 1580.7136678695679 sec\n",
      "\n",
      "Epoch 20 Batch 0 loss 0.057412195950746536\n",
      "Epoch 20 Batch 100 loss 0.03756285831332207\n",
      "Epoch 20 Batch 200 loss 0.06577420234680176\n",
      "Epoch 20 Batch 300 loss 0.05299786850810051\n",
      "Epoch 20 Batch 400 loss 0.04769767448306084\n",
      "Epoch 20 Batch 500 loss 0.06994395703077316\n",
      "Epoch 20 Batch 600 loss 0.07539374381303787\n",
      "Epoch 20 Batch 700 loss 0.05352982506155968\n",
      "Epoch 20 Loss 0.0570\n",
      "Time taken for 1 epoch 1573.934122800827 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
    "   \n",
    "      \n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token* or when the max traget legth is reached\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  #print(sentence)\n",
    "  #print(source_sentence_tokenizer.word_index)\n",
    "\n",
    "  inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_source_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Plot Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "  \n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJpT9D5_OgP6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x197f43d8d88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final translations with Attention Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ i am going to work . _end\n",
      "Predicted translation: voy a trabajar . _end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'I am going to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSx2iM36EZQZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ you need to work smart . _end\n",
      "Predicted translation: necesitas trabajar demasiado duro . _end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'You need to work smart.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
